# ğŸ­ Parody Critics for Jellyfin

A comprehensive system for adding humorous, character-driven movie and TV show reviews to your Jellyfin media server.

## ğŸŒŸ Features

- **ğŸ­ Character-based Critics**: Multiple unique personalities review your content
  - **ğŸ›ï¸ Marco Aurelio**: Stoic philosopher emperor with classical wisdom
  - **ğŸ³ï¸â€âš§ï¸ Rosario Costras**: Hyper-woke social justice activist finding oppression everywhere
  - *More characters coming soon!*

- **ğŸ¨ Dynamic Theming**: Each critic has their own color scheme and visual identity
- **ğŸ“Š RESTful API**: Clean, scalable backend with FastAPI and SQLite
- **ğŸ”„ Automatic Sync**: Integrates with Jellyfin's library for seamless updates
- **ğŸ¤– LLM Integration**: AI-powered review generation (planned)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Jellyfin      â”‚    â”‚   FastAPI    â”‚    â”‚  SQLite DB  â”‚
â”‚   Frontend      â”‚â—„â”€â”€â”€â”‚   Server     â”‚â—„â”€â”€â”€â”‚  critics.db â”‚
â”‚   (JavaScript)  â”‚    â”‚  (REST API)  â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²                     â–²
                              â”‚                     â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                       â”‚   Sync       â”‚            â”‚
                       â”‚   Script     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚  (Python)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Jellyfin    â”‚
                       â”‚   API        â”‚
                       â”‚  (Source)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.11+** (Required for modern FastAPI features)
- **Jellyfin server** running and accessible
- **Ollama** (Optional, for AI-powered reviews)
- **JavaScript Injector plugin** for Jellyfin (for frontend integration)

**Recommended System Requirements:**
- 8GB+ RAM (for LLM processing)
- 10GB+ free disk space (for models and database)
- Network access to Jellyfin and Ollama servers

### Installation

#### ğŸ§™â€â™‚ï¸ Option 1: Setup Wizard (Recommended)

Use our interactive setup wizard for the easiest installation:

```bash
# Clone and navigate
git clone https://github.com/your-username/parody-critics-jellyfin.git
cd parody-critics-jellyfin

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the setup wizard
python simple_wizard.py
```

The wizard will:
- âœ… Check all system dependencies
- âœ… Test connections to Jellyfin and Ollama servers
- âœ… Create optimized `.env` configuration
- âœ… Provide next steps for deployment

**Wizard Options:**
```bash
python simple_wizard.py --help           # Show all options
python simple_wizard.py --demo           # Run with pre-filled demo values
python simple_wizard.py --skip-deps      # Skip dependency checks
python simple_wizard.py --config-only    # Only create configuration
```

#### ğŸ“‹ Option 2: Manual Installation

1. **Clone and setup:**
   ```bash
   git clone https://github.com/your-username/parody-critics-jellyfin.git
   cd parody-critics-jellyfin
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Configure environment:**
   ```bash
   # Copy and edit configuration
   cp .env.example .env
   nano .env  # Update JELLYFIN_URL, LLM settings, etc.
   ```

3. **Initialize database:**
   ```bash
   python run_setup.py
   ```

4. **Start the API server:**
   ```bash
   python -m uvicorn api.main:app --host 0.0.0.0 --port 8000
   ```

5. **Add to Jellyfin:**
   - Install JavaScript Injector plugin
   - Add the frontend script (see `frontend/` folder)

## ğŸ“š API Documentation

The API runs on `http://localhost:8000` with automatic documentation at `/docs`.

### Key Endpoints

- **GET** `/api/critics/{tmdb_id}` - Get critics for a specific movie/show
- **GET** `/api/stats` - Get system statistics
- **GET** `/api/characters` - List all critic characters
- **GET** `/api/health` - Health check

### Example Response

```json
{
  "tmdb_id": "338969",
  "title": "El Vengador TÃ³xico",
  "type": "movie",
  "critics": {
    "marco_aurelio": {
      "author": "Marco Aurelio",
      "emoji": "ğŸ›ï¸",
      "rating": 8,
      "content": "Como emperador y filÃ³sofo, he contemplado muchas transformaciones...",
      "color": "#8B4513"
    },
    "rosario_costras": {
      "author": "Rosario Costras",
      "emoji": "ğŸ³ï¸â€âš§ï¸",
      "rating": 2,
      "content": "Esta pelÃ­cula perpetÃºa mÃºltiples violencias sistÃ©micas...",
      "color": "#FF69B4"
    }
  }
}
```

## ğŸ­ Character System

Each critic is designed with a unique personality and reviewing style:

### ğŸ›ï¸ Marco Aurelio (Stoic)
- **Theme Color:** Brown (`#8B4513`)
- **Style:** Philosophical, accepting, finds wisdom in adversity
- **Quotes:** References to Meditations, Stoic principles

### ğŸ³ï¸â€âš§ï¸ Rosario Costras (Woke)
- **Theme Color:** Hot Pink (`#FF69B4`)
- **Style:** Social justice focused, sees oppression everywhere
- **Language:** Progressive terminology, hashtags, triggers

## ğŸš€ Deployment

### Quick Deploy to Jellyfin Server

If your Jellyfin runs on a remote server (like `stilgar@192.168.45.181`), use the automated deployment script:

```bash
# Make sure SSH key authentication is set up first
./deploy-to-stilgar.sh
```

This script will:
- âœ… Copy all project files to the remote server
- âœ… Set up Python virtual environment
- âœ… Install dependencies and initialize database
- âœ… Create systemd service for the API
- âœ… Install JavaScript client in Jellyfin web directory
- âœ… Start the API service automatically

After deployment:
```bash
# SSH to your Jellyfin server
ssh stilgar@192.168.45.181

# Navigate to project directory
cd parody-critics

# Activate environment and sync your Jellyfin library
source venv/bin/activate
python scripts/jellyfin_sync.py --jellyfin-url http://localhost:8096 --api-key YOUR_API_KEY

# Restart Jellyfin to load the new JavaScript client
sudo systemctl restart jellyfin
```

### Manual Deployment

1. **Copy project to your Jellyfin server:**
   ```bash
   rsync -avz ./ user@your-server:/path/to/parody-critics/
   ```

2. **Set up environment:**
   ```bash
   # On the server
   cd /path/to/parody-critics
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   python run_setup.py
   ```

3. **Configure for your environment:**
   ```bash
   # Copy and edit environment file
   cp .env.stilgar .env
   nano .env  # Update JELLYFIN_API_KEY and other settings
   ```

4. **Start the API:**
   ```bash
   # Development
   source venv/bin/activate
   python -m uvicorn api.main:app --host 0.0.0.0 --port 8000

   # Production (with systemd)
   sudo cp parody-critics-api.service /etc/systemd/system/
   sudo systemctl enable parody-critics-api.service
   sudo systemctl start parody-critics-api.service
   ```

5. **Install JavaScript client:**
   ```bash
   # Copy to your Jellyfin web directory
   sudo cp frontend/parody-critics-api-client.js /opt/jellyfin/jellyfin-web/
   ```

### Environment Variables

The API supports environment-based configuration:

```bash
# Environment
PARODY_CRITICS_ENV=stilgar          # development, stilgar, production

# API Configuration
PARODY_CRITICS_HOST=0.0.0.0         # Bind address
PARODY_CRITICS_PORT=8000            # Port number

# Database
PARODY_CRITICS_DB_PATH=/path/to/critics.db

# Jellyfin
JELLYFIN_URL=http://localhost:8096
JELLYFIN_API_KEY=your-api-key

# CORS (comma-separated URLs)
PARODY_CRITICS_CORS_ORIGINS=http://localhost:8096,http://server:8096
```

### Network Configuration

The JavaScript client automatically detects the API URL:
- **Local development**: Uses `http://localhost:8000/api`
- **Remote deployment**: Uses `http://YOUR_SERVER_IP:8000/api`

Make sure:
- âœ… Port 8000 is open on your server firewall
- âœ… Jellyfin can access the API (same network/CORS configured)
- âœ… API service starts automatically on boot

## ğŸ”§ Development

### Project Structure
```
parody-critics-api/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # FastAPI server
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.sql           # Database schema
â”‚   â”œâ”€â”€ init_db.py          # DB initialization
â”‚   â””â”€â”€ critics.db          # SQLite database (generated)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ jellyfin_sync.py    # Sync with Jellyfin (planned)
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ parody-critics.js   # JavaScript for Jellyfin
â””â”€â”€ run_setup.py            # Setup script
```

### Adding New Characters

1. Update `database/schema.sql` with new character data
2. Add character theme in `frontend/parody-critics.js`
3. Create personality prompts for LLM generation
4. Re-run database initialization

## ğŸ¤– AI Integration

### LLM Integration with Ollama

The system integrates with **Ollama** for local AI-powered review generation:

#### Supported Models
- **QWen3:8B**: Primary model for fast, coherent reviews
- **GPT-OSS:20B**: Secondary/fallback model for complex analysis
- **Custom Models**: Any Ollama-compatible model

#### Setup Ollama Integration

1. **Install Ollama** (if not already installed):
   ```bash
   # Linux/macOS
   curl -fsSL https://ollama.com/install.sh | sh

   # Or visit https://ollama.com for other installation methods
   ```

2. **Pull recommended models:**
   ```bash
   ollama pull qwen3:8b        # Primary model (~5GB)
   ollama pull gpt-oss:20b     # Secondary model (~12GB)
   ```

3. **Configure in the setup wizard:**
   ```bash
   python simple_wizard.py
   # The wizard will auto-detect your Ollama models and configure them
   ```

4. **Manual configuration (optional):**
   ```bash
   # .env file
   LLM_OLLAMA_URL=http://localhost:11434        # Ollama server URL
   LLM_PRIMARY_MODEL=qwen3:8b                   # Default model
   LLM_SECONDARY_MODEL=gpt-oss:20b              # Fallback model
   LLM_TIMEOUT=180                              # Request timeout (seconds)
   LLM_MAX_RETRIES=2                            # Retry attempts
   LLM_ENABLE_FALLBACK=true                     # Use fallback model on failure
   ```

#### LLM Features
- **ğŸ­ Character Consistency**: Each critic maintains their unique voice
- **ğŸ”„ Automatic Fallback**: Switches to secondary model if primary fails
- **âš¡ Caching**: Reviews are cached to avoid regeneration
- **ğŸ›¡ï¸ Privacy**: All processing done locally with Ollama
- **âš–ï¸ Load Balancing**: Distributes requests across available models

### Cloud LLM Support (Future)
- **OpenAI GPT-4**: Premium, highest quality
- **Anthropic Claude**: Great reasoning and character consistency
- **Google Gemini**: Multimodal capabilities

## ğŸ“Š Database Schema

The SQLite database includes tables for:
- `media` - Movie and TV show metadata
- `characters` - Critic personality definitions
- `critics` - Generated reviews
- `sync_log` - Synchronization tracking

## ğŸ› ï¸ Troubleshooting

### Setup Wizard Issues

**Wizard fails with "module not found" errors:**
```bash
# Make sure you're in the virtual environment
source venv/bin/activate
pip install -r requirements.txt
```

**Connection test failures:**
- **Jellyfin**: Check URL format (include `http://`) and port
- **Ollama**: Ensure Ollama is running (`ollama serve`)
- **Models**: Pull required models (`ollama pull qwen3:8b`)

**Port 8000 already in use:**
```bash
# Check what's using the port
lsof -i :8000
# Kill the process or use a different port
```

**EOF errors during interactive setup:**
- Use `--demo` mode for non-interactive testing
- Ensure terminal supports input (not running in background)

### LLM Integration Issues

**Models not detected:**
```bash
# Check Ollama status
ollama list
ollama serve  # If not running

# Test connection manually
curl http://localhost:11434/api/tags
```

**Generation timeouts:**
- Increase `LLM_TIMEOUT` in `.env`
- Use smaller models (qwen3:8b instead of larger models)
- Check system resources (RAM/CPU)

**Character inconsistency:**
- Update character prompts in database
- Clear review cache
- Tune model temperature settings

## ğŸ› Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Jellyfin team for the amazing media server
- JavaScript Injector plugin developers
- FastAPI and SQLite communities

---

*"The spice must flow... and so must the parody reviews!"* ğŸ­

Made with â¤ï¸ by SAL-9000 and the Landsraad Homelab crew